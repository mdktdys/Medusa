from io import BytesIO

from docx import Document
from docx.document import Document as DocumentObject
from docx.table import Table

from utils.logger import logger


def clean_trash(string: str) -> str:
    return string.replace('(ÑƒÐ»Ð·Ð²Ð°Ð»Ð¸Ð´Ð¸7Ð°)','')

def all_equal(items: list[str]) -> bool:
    return len(set(items)) <= 1


def clean_dirty_string(string: str) -> str:
    return (
        string.replace(" ", "")
        .replace(".", "")
        .replace(",", "")
        .replace("-", "")
        .replace("_", "")
        .replace("\n", " ")
        .replace("\t", "")
        .replace("â€”", "")
        .replace("â€”", "")
    ).lower().replace(' ','')


async def parse_zamena_v3(stream: BytesIO, session):
    exceptions: list = []
    
    docx: DocumentObject = Document(stream)
    all_rows: list[list[str]] = extract_all_tables_to_rows(docx.tables)
    work_rows: list = all_rows
    # header_paragraphs: List[Paragraph] = docx.paragraphs    
    
    # Ð£Ð´Ð°Ð»ÐµÐ½Ð¸Ðµ ÑÑ‚Ð¾Ð»Ð±Ñ†Ð° Ð’Ñ€ÐµÐ¼Ñ
    first_row = work_rows[0]
    if first_row[0] == 'Ð’Ñ€ÐµÐ¼Ñ':
        for row in work_rows:
            row.pop(0)
            
    # Ð£Ð´Ð°Ð»ÐµÐ½Ð¸Ðµ ÑÑ‚Ñ€Ð¾ÐºÐ¸ Ñ…ÐµÐ´ÐµÑ€Ð¾Ð²
    if first_row[0] == 'ÐŸÐ°Ñ€Ð°':
        work_rows.pop(0)
        
    # ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° Ð¿ÑƒÑÑ‚Ñ‹Ñ… ÑÑ‚Ñ€Ð¾Ðº
    work_rows = [sublist for sublist in work_rows if any(item != "" for item in sublist)]

    from src.api_v1.groups.crud import get_groups_normalized_contains

    # Ð’Ð¾ÑÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ ÑÑ‚Ñ€Ð¾Ðº Ñ Ð¿Ð¾Ð»Ð½Ð¾Ð¹ Ð·Ð°Ð¼ÐµÐ½Ð¾Ð¹ ['','','21ÐŸ-2','',''] -> ['21ÐŸ-2','21ÐŸ-2','21ÐŸ-2','21ÐŸ-2','21ÐŸ-2']
    for row in work_rows:
        non_empty_cells: list[str] = [cell for cell in row if isinstance(cell, str) and cell.strip()]
        if not non_empty_cells:
            continue
        if len(non_empty_cells) == 1:
            non_empty_cell: str = clean_dirty_string(non_empty_cells[0])
            groups = await get_groups_normalized_contains(session=session, raw_name=non_empty_cell)
            if groups:
                group = groups[0]
                row[:] = [group.name] * len(row)
            else:
                print(f'ðŸ”´ ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð° Ð³Ñ€ÑƒÐ¿Ð¿Ð° -> {non_empty_cell}')
            
    # Ð’Ð¾ÑÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¾Ñ‚Ð¾Ñ€Ð²Ð°Ð½Ð½Ñ‹Ñ… ÑÑ‚Ñ€Ð¾Ðº
    # ['4,5', '', '', 'ÐŸÑ€Ð°Ð²Ð¾Ð²Ñ‹Ðµ Ð¾ÑÐ½Ð¾Ð²Ñ‹ Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¸Ð²Ð½Ð¾-', 'ÐœÑƒÐ·Ð°Ñ„Ð°Ñ€Ð¾Ð² Ð¤.Ð¤.', '112']
    # ['', '', '', 'Ñ€Ð¾Ð·Ñ‹ÑÐºÐ½Ð¾Ð¹ \nÐ´ÐµÑÑ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸', '', '']
    # -> ['4,5', '', '', 'ÐŸÑ€Ð°Ð²Ð¾Ð²Ñ‹Ðµ Ð¾ÑÐ½Ð¾Ð²Ñ‹ Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¸Ð²Ð½Ð¾-Ñ€Ð¾Ð·Ñ‹ÑÐºÐ½Ð¾Ð¹ \nÐ´ÐµÑÑ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸', 'ÐœÑƒÐ·Ð°Ñ„Ð°Ñ€Ð¾Ð² Ð¤.Ð¤.', '112']
    merged_rows: list[list[str]] = []
    for row in work_rows:
        if row[0] == '' and merged_rows:
            prev_row: list[str] = merged_rows[-1]
            prev_row[3] = (prev_row[3] + row[3]).strip()
        else:
            merged_rows.append(row)
    work_rows = list(merged_rows)
        
    # Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´ Ð¿Ð°Ñ€ 3,4 Ð½Ð° Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ðµ ÑÑ‚Ñ€Ð¾ÐºÐ¸
    extracted: list = []
    for row in work_rows:
        timings_text = row[0]

        if not timings_text.replace(',','').isdigit():
            extracted.append(row)
            continue
    
        cell: str = timings_text.replace('.', ',')
    
        if cell[0] == ',':
            cell = cell[1:]
        
        if cell[-1] == ',':
            cell = cell[:-1]
        
        timings: list[str] = cell.split(',')
    
        if len(timings) > 1:
            for timing in timings:
                copy_row = row.copy()
                copy_row[0] = timing
                extracted.append(copy_row)
        else:
            extracted.append(row)

    work_rows = list(extracted)


    # ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° Ð¾Ñ‚ Ð»Ð¸ÑˆÐ½Ð¸Ñ… ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²
    work_rows = [[clean_dirty_string(cell) for cell in row] for row in work_rows]
    
    # ÐŸÐµÑ€ÐµÐ²Ð¾Ð´ Ð² Ð°Ð¹Ð´Ð¸ÑˆÐ½Ð¸ÐºÐ¸
    from src.api_v1.disciplines.crud import find_disciplines_by_alias_or_name
    for row in work_rows:
        if all_equal(row):
            group_text: str = clean_trash(row[0])
            groups = await get_groups_normalized_contains(
                session=session,
                raw_name=group_text
            )

            if not groups:
                raise Exception(f'ðŸ”´ ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð° Ð³Ñ€ÑƒÐ¿Ð¿Ð° {group_text}')
            if len(groups) > 1:
                raise Exception(f'ðŸ”´ Ð‘Ð¾Ð»ÑŒÑˆÐµ 1 ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹ {group_text}')

            group_id = str(groups[0].id)
            row[:] = [group_id] * len(row)

        else:
            course_text: str = row[3]
            founded_disciplines = await find_disciplines_by_alias_or_name(
                session = session,
                raw = course_text
            )
            
            if not founded_disciplines:
                exceptions.append(f'ðŸ”´ ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð° Ð´Ð¸ÑÑ†Ð¸Ð¿Ð»Ð¸Ð½Ð° {course_text}')
                continue
            if len(founded_disciplines) > 1:
                raise Exception(f'ðŸ”´ Ð‘Ð¾Ð»ÑŒÑˆÐµ 1 ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ Ð´Ð¸ÑÑ†Ð¸Ð¿Ð»Ð¸Ð½ {course_text}')
            
    if len(exceptions) > 0:
        for exception in exceptions:
            logger.error(exception)

        raise Exception(exceptions)
            
    
    for row in work_rows:
        print(row)
    
    return {
        'result': 'completed',
        'work_rows': str(work_rows)
    }
    
    
def extract_all_tables_to_rows(tables: list[Table]) -> list[list[str]]:
    rows: list = []
    for table in tables:
        for row in table.rows:
            data: list = []
            for cell in row.cells:
                cell_text: str = cell.text.strip()
                if cell.tables:
                    nested_table_rows: list = extract_all_tables_to_rows(cell.tables)
                    data.extend(nested_table_rows)
                else:
                    data.append(cell_text)
            rows.append(data)
    return rows
