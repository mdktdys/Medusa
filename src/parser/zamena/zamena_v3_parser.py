from io import BytesIO

from docx import Document
from docx.document import Document as DocumentObject
from docx.table import Table

from src.alchemy.database_local import (Zamena, ZamenaGroup, ZamenaGroupType,
                                        ZamenaSwaps)
from src.utils.logger import logger


def clean_trash(string: str) -> str:
    return string.replace('(ÑƒÐ»Ð·Ð²Ð°Ð»Ð¸Ð´Ð¸7Ð°)','')

def all_equal(items: list[str]) -> bool:
    return len(set(items)) <= 1


def clean_dirty_string(string: str) -> str:
    return (
        string.replace(" ", "")
        .replace(".", "")
        .replace(",", "")
        .replace("-", "")
        .replace("_", "")
        .replace("\n", " ")
        .replace("\t", "")
        .replace("â€”", "")
        .replace("â€”", "")
    ).lower().replace(' ','')


async def parse_zamena_v3(stream: BytesIO, session):
    exceptions: list = []
    zamena_swaps = []
    
    docx: DocumentObject = Document(stream)
    all_rows: list[list[str]] = extract_all_tables_to_rows(docx.tables)
    work_rows: list = all_rows
    # header_paragraphs: List[Paragraph] = docx.paragraphs    
    
    first_row = work_rows[0]
    # # Ð£Ð´Ð°Ð»ÐµÐ½Ð¸Ðµ ÑÑ‚Ð¾Ð»Ð±Ñ†Ð° Ð’Ñ€ÐµÐ¼Ñ
    # if first_row[0] == 'Ð’Ñ€ÐµÐ¼Ñ':
    #     for row in work_rows:
    #         row.pop(0)
            
    # Ð£Ð´Ð°Ð»ÐµÐ½Ð¸Ðµ ÑÑ‚Ñ€Ð¾ÐºÐ¸ Ñ…ÐµÐ´ÐµÑ€Ð¾Ð²
    if first_row[0] == 'Ð’Ñ€ÐµÐ¼Ñ':
        work_rows.pop(0)
        
    # ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° Ð¿ÑƒÑÑ‚Ñ‹Ñ… ÑÑ‚Ñ€Ð¾Ðº
    work_rows = [sublist for sublist in work_rows if any(item != "" for item in sublist)]


    # ÐŸÑ€Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹ Ð² Ð¿ÐµÑ€Ð²ÑƒÑŽ ÑÑ‡ÐµÐ¹ÐºÑƒ
    # ['25ÐŸÐ”-2', '25ÐŸÐ”-2', '25ÐŸÐ”-2', '25ÐŸÐ”-2', '25ÐŸÐ”-2', '25ÐŸÐ”-2', '25ÐŸÐ”-2']
    # ['', '3', '', '', 'ÐœÐ°Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸ÐºÐ°', 'Ð“Ð°Ð¹ÑÐ¸Ð½ Ð˜.Ð˜.', '223']
    # -> 
    # ['25ÐŸÐ”-2', '3', '', '', 'ÐœÐ°Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸ÐºÐ°', 'Ð“Ð°Ð¹ÑÐ¸Ð½ Ð˜.Ð˜.', '223']
    group_name: str = work_rows[0][0]
    for row in work_rows:
        if row[0] == '':
            row[0] = group_name
        else:
            group_name = row[0]


    from src.api_v1.groups.crud import get_groups_normalized_contains

    # Ð’Ð¾ÑÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ ÑÑ‚Ñ€Ð¾Ðº Ñ Ð¿Ð¾Ð»Ð½Ð¾Ð¹ Ð·Ð°Ð¼ÐµÐ½Ð¾Ð¹ ['','','21ÐŸ-2','',''] -> ['21ÐŸ-2','21ÐŸ-2','21ÐŸ-2','21ÐŸ-2','21ÐŸ-2']
    # for row in work_rows:
    #     non_empty_cells: list[str] = [cell for cell in row if isinstance(cell, str) and cell.strip()]
    #     if not non_empty_cells:
    #         continue
    #     if len(non_empty_cells) == 1:
    #         non_empty_cell: str = clean_dirty_string(non_empty_cells[0])
    #         groups = await get_groups_normalized_contains(session=session, raw_name=non_empty_cell)
    #         if groups:
    #             group = groups[0]
    #             row[:] = [group.name] * len(row)
    #         else:
    #             print(f'ðŸ”´ ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð° Ð³Ñ€ÑƒÐ¿Ð¿Ð° -> {non_empty_cell}')
    # Ð’Ð¾ÑÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¾Ñ‚Ð¾Ñ€Ð²Ð°Ð½Ð½Ñ‹Ñ… ÑÑ‚Ñ€Ð¾Ðº
    # ['4,5', '', '', 'ÐŸÑ€Ð°Ð²Ð¾Ð²Ñ‹Ðµ Ð¾ÑÐ½Ð¾Ð²Ñ‹ Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¸Ð²Ð½Ð¾-', 'ÐœÑƒÐ·Ð°Ñ„Ð°Ñ€Ð¾Ð² Ð¤.Ð¤.', '112']
    # ['', '', '', 'Ñ€Ð¾Ð·Ñ‹ÑÐºÐ½Ð¾Ð¹ \nÐ´ÐµÑÑ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸', '', '']
    # -> ['4,5', '', '', 'ÐŸÑ€Ð°Ð²Ð¾Ð²Ñ‹Ðµ Ð¾ÑÐ½Ð¾Ð²Ñ‹ Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¸Ð²Ð½Ð¾-Ñ€Ð¾Ð·Ñ‹ÑÐºÐ½Ð¾Ð¹ \nÐ´ÐµÑÑ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸', 'ÐœÑƒÐ·Ð°Ñ„Ð°Ñ€Ð¾Ð² Ð¤.Ð¤.', '112']
    # merged_rows: list[list[str]] = []
    # for row in work_rows:
    #     if row[0] == '' and merged_rows:
    #         prev_row: list[str] = merged_rows[-1]
    #         prev_row[3] = (prev_row[3] + row[3]).strip()
    #     else:
    #         merged_rows.append(row)
    # work_rows = list(merged_rows)
    # Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´ Ð¿Ð°Ñ€ 3,4 Ð½Ð° Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ðµ ÑÑ‚Ñ€Ð¾ÐºÐ¸
    extracted: list = []
    for row in work_rows:
        timings_text = row[1]

        if not timings_text.replace(',','').isdigit():
            extracted.append(row)
            continue
    
        cell: str = timings_text.replace('.', ',')
    
        if cell[0] == ',':
            cell = cell[1:]
        
        if cell[-1] == ',':
            cell = cell[:-1]
        
        timings: list[str] = cell.split(',')
    
        if len(timings) > 1:
            for timing in timings:
                copy_row = row.copy()
                copy_row[1] = timing
                extracted.append(copy_row)
        else:
            extracted.append(row)

    work_rows = list(extracted)
    
    # # ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° Ð¾Ñ‚ Ð»Ð¸ÑˆÐ½Ð¸Ñ… ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²
    work_rows = [[clean_dirty_string(cell) for cell in row] for row in work_rows]
    
    # # ÐŸÐµÑ€ÐµÐ²Ð¾Ð´ Ð² Ð°Ð¹Ð´Ð¸ÑˆÐ½Ð¸ÐºÐ¸
    from src.api_v1.disciplines.crud import \
        find_group_disciplines_by_alias_or_name_or_code_discipline_name
    
    current_group = None
    full_swap_groups_ids = []
    for row in work_rows:
        group_text: str = clean_trash(row[0])
        groups = await get_groups_normalized_contains(
            session=session,
            raw_name=group_text
        )

        if not groups:
            raise Exception(f'ðŸ”´ ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð° Ð³Ñ€ÑƒÐ¿Ð¿Ð° {group_text}')
        if len(groups) > 1:
            raise Exception(f'ðŸ”´ Ð‘Ð¾Ð»ÑŒÑˆÐµ 1 ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹ {group_text}')

        group = groups[0]
        # row[:] = [group] * len(row)
        current_group = group

        if all_equal(row):
            full_swap_groups_ids.append(group.id)
            continue
        
        course_text: str = row[4]
        course = None
        if course_text != 'Ð½ÐµÑ‚':
            founded_disciplines = await find_group_disciplines_by_alias_or_name_or_code_discipline_name(
                session = session,
                group = group,
                raw = course_text
            )
        
            if len(founded_disciplines) == 0:
                exceptions.append(f'ðŸ”´ ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð° Ð´Ð¸ÑÑ†Ð¸Ð¿Ð»Ð¸Ð½Ð° {course_text} Ð´Ð»Ñ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹ {current_group.name}')
                continue
            if len(founded_disciplines) > 1:
                raise Exception(f'ðŸ”´ Ð‘Ð¾Ð»ÑŒÑˆÐµ 1 ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ Ð´Ð¸ÑÑ†Ð¸Ð¿Ð»Ð¸Ð½ {course_text} Ð´Ð»Ñ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹ {current_group.name} -> {founded_disciplines}')
            course = founded_disciplines[0]
            
            
        cabinet_text: str = row[6]
        cabinet = None
        if cabinet_text != '':
            from src.parser.schedule.schedule_parser_v3 import \
                find_cabinet_in_cabinets_by_name
            cabinet = await find_cabinet_in_cabinets_by_name(session = session, raw_name = cabinet_text)
            
            if cabinet is None:
                exceptions.append(f'ðŸ”´ ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½ ÐºÐ°Ð±Ð¸Ð½ÐµÑ‚ {cabinet_text}')
                
        teacher_text: str = row[5]
        teacher = None
        if teacher != '':
            from src.parser.schedule.schedule_parser_v3 import \
                find_teacher_in_teachers_by_name
            teacher = await find_teacher_in_teachers_by_name(session = session, raw_name = teacher_text)
            
            if teacher is None:
                exceptions.append(f'ðŸ”´ ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ð¿Ñ€ÐµÐ¿Ð¾Ð´Ð°Ð²Ð°Ñ‚ÐµÐ»ÑŒ {teacher_text}')
        
        timing = int(row[1])
        
        if len(exceptions) != 0:
            continue
        
        # swap = ZamenaSwaps(
        #     group_id = group.id,
        #     timing_id = timing,
        #     teacher_id = teacher.id,
        #     discipline_id = course.id,
        #     cabinet_id = cabinet.id
        # )
        # zamena_swaps.append(swap)
        
    
    # zamena = Zamena(
    #     date_ = ,
    #     saturday_timings = False,
    #     file_url = '',
    #     file_hash = '',   
    # )
    
    # for zamena_swap in zamena_swaps:
    #     zamena_swap.zamena_id = zamena.id
        
    for row in work_rows:
        print(row)
            
    if len(exceptions) > 0:
        for exception in exceptions:
            logger.error(exception)

        raise Exception(exceptions)
    
    
    return {
        'result': 'completed',
        'work_rows': str(work_rows)
    }
    
    
def extract_all_tables_to_rows(tables: list[Table]) -> list[list[str]]:
    rows: list = []
    for table in tables:
        for row in table.rows:
            data: list = []
            for cell in row.cells:
                cell_text: str = cell.text.strip()
                if cell.tables:
                    nested_table_rows: list = extract_all_tables_to_rows(cell.tables)
                    data.extend(nested_table_rows)
                else:
                    data.append(cell_text)
            rows.append(data)
    return rows